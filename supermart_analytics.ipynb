{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn plotly gradio scikit-learn"
      ],
      "metadata": {
        "id": "Tlzy-6_AL50I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f477062-7d35-4f8b-97c4-0d5d0d8a6ece"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CJhRG3cdL0GV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "bc9752cf-e382-4671-9fce-f012523f0c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2955df7d1ef9826355.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2955df7d1ef9826355.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2955df7d1ef9826355.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class SupermartAnalytics:\n",
        "    def __init__(self):\n",
        "        self.df = None\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = []\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        \"\"\"Load and preprocess the dataset\"\"\"\n",
        "        try:\n",
        "            self.df = pd.read_csv(file_path)\n",
        "\n",
        "            # Data preprocessing\n",
        "            self.df['Order Date'] = pd.to_datetime(self.df['Order Date'], errors='coerce')\n",
        "            self.df['Day'] = self.df['Order Date'].dt.day\n",
        "            self.df['Month_Num'] = self.df['Order Date'].dt.month\n",
        "            self.df['Year'] = self.df['Order Date'].dt.year\n",
        "            self.df['Month_Name'] = self.df['Order Date'].dt.strftime('%B')\n",
        "            self.df['Weekday'] = self.df['Order Date'].dt.dayofweek\n",
        "\n",
        "            # Remove any rows with missing values\n",
        "            self.df = self.df.dropna()\n",
        "\n",
        "            # Remove duplicates\n",
        "            self.df = self.df.drop_duplicates()\n",
        "\n",
        "            return f\"✅ Data loaded successfully! Shape: {self.df.shape}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error loading data: {str(e)}\"\n",
        "\n",
        "    def get_data_overview(self):\n",
        "        \"\"\"Generate data overview with properly formatted tables\"\"\"\n",
        "        if self.df is None:\n",
        "            return \"⚠️ Please load data first\", None, None, None\n",
        "\n",
        "        # Basic info\n",
        "        basic_info = f\"\"\"\n",
        "        ## 📊 Dataset Overview\n",
        "\n",
        "        **Shape:** {self.df.shape[0]} rows × {self.df.shape[1]} columns\n",
        "        **Date Range:** {self.df['Order Date'].min().strftime('%Y-%m-%d')} to {self.df['Order Date'].max().strftime('%Y-%m-%d')}\n",
        "        \"\"\"\n",
        "\n",
        "        # Data types and info table\n",
        "        dtypes_info = []\n",
        "        for col in self.df.columns:\n",
        "            dtypes_info.append({\n",
        "                'Column': col,\n",
        "                'Data Type': str(self.df[col].dtype),\n",
        "                'Non-Null Count': self.df[col].count(),\n",
        "                'Null Count': self.df[col].isnull().sum(),\n",
        "                'Unique Values': self.df[col].nunique()\n",
        "            })\n",
        "\n",
        "        dtypes_df = pd.DataFrame(dtypes_info)\n",
        "\n",
        "        # Basic statistics for numerical columns\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        if len(numeric_cols) > 0:\n",
        "            numeric_stats = self.df[numeric_cols].describe().round(2).T\n",
        "            numeric_stats.reset_index(inplace=True)\n",
        "            numeric_stats.rename(columns={'index': 'Column'}, inplace=True)\n",
        "        else:\n",
        "            numeric_stats = pd.DataFrame({'Message': ['No numeric columns found']})\n",
        "\n",
        "        # Sample data\n",
        "        sample_data = self.df.head(10)\n",
        "\n",
        "        return basic_info, dtypes_df, numeric_stats, sample_data\n",
        "\n",
        "    def create_category_analysis(self):\n",
        "        \"\"\"Analyze sales by category with proper formatting\"\"\"\n",
        "        if self.df is None:\n",
        "            return None, None\n",
        "\n",
        "        # Sales by Category\n",
        "        category_analysis = []\n",
        "        for category in self.df['Category'].unique():\n",
        "            cat_data = self.df[self.df['Category'] == category]\n",
        "            category_analysis.append({\n",
        "                'Category': category,\n",
        "                'Total Sales': cat_data['Sales'].sum(),\n",
        "                'Average Sales': cat_data['Sales'].mean(),\n",
        "                'Order Count': len(cat_data),\n",
        "                'Total Profit': cat_data['Profit'].sum(),\n",
        "                'Average Discount': cat_data['Discount'].mean()\n",
        "            })\n",
        "\n",
        "        category_df = pd.DataFrame(category_analysis)\n",
        "        category_df = category_df.sort_values('Total Sales', ascending=False)\n",
        "\n",
        "        # Add percentage of total sales\n",
        "        category_df['Sales Percentage'] = (category_df['Total Sales'] / category_df['Total Sales'].sum() * 100).round(2)\n",
        "\n",
        "        # Format numerical columns\n",
        "        category_df['Total Sales'] = category_df['Total Sales'].round(2)\n",
        "        category_df['Average Sales'] = category_df['Average Sales'].round(2)\n",
        "        category_df['Total Profit'] = category_df['Total Profit'].round(2)\n",
        "        category_df['Average Discount'] = (category_df['Average Discount'] * 100).round(2)\n",
        "\n",
        "        # Create visualization\n",
        "        fig = px.bar(\n",
        "            category_df,\n",
        "            x='Category',\n",
        "            y='Total Sales',\n",
        "            title='Sales Performance by Category',\n",
        "            labels={'Total Sales': 'Total Sales (₹)', 'Category': 'Product Category'},\n",
        "            color='Total Sales',\n",
        "            color_continuous_scale='viridis'\n",
        "        )\n",
        "        fig.update_layout(xaxis_tickangle=-45, height=500)\n",
        "\n",
        "        return fig, category_df\n",
        "\n",
        "    def create_temporal_analysis(self):\n",
        "        \"\"\"Analyze sales trends over time\"\"\"\n",
        "        if self.df is None:\n",
        "            return None, None\n",
        "\n",
        "        # Monthly sales trend\n",
        "        monthly_data = []\n",
        "        for year in sorted(self.df['Year'].unique()):\n",
        "            for month in range(1, 13):\n",
        "                month_data = self.df[(self.df['Year'] == year) & (self.df['Month_Num'] == month)]\n",
        "                if not month_data.empty:\n",
        "                    monthly_data.append({\n",
        "                        'Year': year,\n",
        "                        'Month': month,\n",
        "                        'Period': f\"{year}-{month:02d}\",\n",
        "                        'Sales': month_data['Sales'].sum(),\n",
        "                        'Orders': len(month_data),\n",
        "                        'Profit': month_data['Profit'].sum()\n",
        "                    })\n",
        "\n",
        "        monthly_df = pd.DataFrame(monthly_data)\n",
        "\n",
        "        # Create time series plot\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=monthly_df['Period'],\n",
        "            y=monthly_df['Sales'],\n",
        "            mode='lines+markers',\n",
        "            name='Monthly Sales',\n",
        "            line=dict(color='blue', width=2)\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Sales Trend Over Time',\n",
        "            xaxis_title='Time Period',\n",
        "            yaxis_title='Sales Amount (₹)',\n",
        "            xaxis_tickangle=-45,\n",
        "            height=500\n",
        "        )\n",
        "\n",
        "        # Year-wise summary\n",
        "        yearly_summary = []\n",
        "        for year in sorted(self.df['Year'].unique()):\n",
        "            year_data = self.df[self.df['Year'] == year]\n",
        "            yearly_summary.append({\n",
        "                'Year': year,\n",
        "                'Total Sales': year_data['Sales'].sum(),\n",
        "                'Total Orders': len(year_data),\n",
        "                'Average Order Value': year_data['Sales'].mean(),\n",
        "                'Total Profit': year_data['Profit'].sum()\n",
        "            })\n",
        "\n",
        "        yearly_df = pd.DataFrame(yearly_summary)\n",
        "        yearly_df['Total Sales'] = yearly_df['Total Sales'].round(2)\n",
        "        yearly_df['Average Order Value'] = yearly_df['Average Order Value'].round(2)\n",
        "        yearly_df['Total Profit'] = yearly_df['Total Profit'].round(2)\n",
        "\n",
        "        return fig, yearly_df\n",
        "\n",
        "    def create_regional_analysis(self):\n",
        "        \"\"\"Analyze sales by region and city\"\"\"\n",
        "        if self.df is None:\n",
        "            return None, None\n",
        "\n",
        "        # Regional analysis\n",
        "        regional_data = []\n",
        "        for region in self.df['Region'].unique():\n",
        "            region_data = self.df[self.df['Region'] == region]\n",
        "            regional_data.append({\n",
        "                'Region': region,\n",
        "                'Total Sales': region_data['Sales'].sum(),\n",
        "                'Average Sales': region_data['Sales'].mean(),\n",
        "                'Order Count': len(region_data),\n",
        "                'Total Profit': region_data['Profit'].sum(),\n",
        "                'Unique Cities': region_data['City'].nunique()\n",
        "            })\n",
        "\n",
        "        regional_df = pd.DataFrame(regional_data)\n",
        "        regional_df = regional_df.sort_values('Total Sales', ascending=False)\n",
        "\n",
        "        # Format columns\n",
        "        regional_df['Total Sales'] = regional_df['Total Sales'].round(2)\n",
        "        regional_df['Average Sales'] = regional_df['Average Sales'].round(2)\n",
        "        regional_df['Total Profit'] = regional_df['Total Profit'].round(2)\n",
        "\n",
        "        # Top cities analysis\n",
        "        city_data = []\n",
        "        for city in self.df['City'].unique():\n",
        "            city_info = self.df[self.df['City'] == city]\n",
        "            city_data.append({\n",
        "                'City': city,\n",
        "                'Region': city_info['Region'].iloc[0],\n",
        "                'State': city_info['State'].iloc[0],\n",
        "                'Total Sales': city_info['Sales'].sum(),\n",
        "                'Order Count': len(city_info),\n",
        "                'Average Sales': city_info['Sales'].mean()\n",
        "            })\n",
        "\n",
        "        city_df = pd.DataFrame(city_data)\n",
        "        city_df = city_df.sort_values('Total Sales', ascending=False).head(15)\n",
        "\n",
        "        # Format columns\n",
        "        city_df['Total Sales'] = city_df['Total Sales'].round(2)\n",
        "        city_df['Average Sales'] = city_df['Average Sales'].round(2)\n",
        "\n",
        "        # Create visualization\n",
        "        fig = make_subplots(\n",
        "            rows=1, cols=2,\n",
        "            subplot_titles=('Sales by Region', 'Top 15 Cities by Sales'),\n",
        "            specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}]]\n",
        "        )\n",
        "\n",
        "        # Pie chart for regions\n",
        "        fig.add_trace(\n",
        "            go.Pie(labels=regional_df['Region'], values=regional_df['Total Sales'], name=\"Regional Sales\"),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Bar chart for top cities\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=city_df['City'], y=city_df['Total Sales'], name=\"City Sales\"),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        fig.update_layout(title_text=\"Regional and City-wise Sales Analysis\", height=500)\n",
        "        fig.update_xaxes(tickangle=-45, row=1, col=2)\n",
        "\n",
        "        return fig, regional_df, city_df\n",
        "\n",
        "    def create_profit_analysis(self):\n",
        "        \"\"\"Analyze profit margins and discount impact\"\"\"\n",
        "        if self.df is None:\n",
        "            return None, None\n",
        "\n",
        "        # Calculate profit margin\n",
        "        self.df['Profit_Margin'] = (self.df['Profit'] / self.df['Sales']) * 100\n",
        "\n",
        "        # Category-wise profit analysis\n",
        "        profit_data = []\n",
        "        for category in self.df['Category'].unique():\n",
        "            cat_data = self.df[self.df['Category'] == category]\n",
        "            profit_data.append({\n",
        "                'Category': category,\n",
        "                'Total Profit': cat_data['Profit'].sum(),\n",
        "                'Average Profit Margin': cat_data['Profit_Margin'].mean(),\n",
        "                'Average Discount': cat_data['Discount'].mean(),\n",
        "                'Total Sales': cat_data['Sales'].sum(),\n",
        "                'Orders': len(cat_data)\n",
        "            })\n",
        "\n",
        "        profit_df = pd.DataFrame(profit_data)\n",
        "        profit_df = profit_df.sort_values('Total Profit', ascending=False)\n",
        "\n",
        "        # Format columns\n",
        "        profit_df['Total Profit'] = profit_df['Total Profit'].round(2)\n",
        "        profit_df['Average Profit Margin'] = profit_df['Average Profit Margin'].round(2)\n",
        "        profit_df['Average Discount'] = (profit_df['Average Discount'] * 100).round(2)\n",
        "        profit_df['Total Sales'] = profit_df['Total Sales'].round(2)\n",
        "\n",
        "        # Create scatter plot\n",
        "        fig = px.scatter(\n",
        "            self.df,\n",
        "            x='Discount',\n",
        "            y='Profit_Margin',\n",
        "            size='Sales',\n",
        "            color='Category',\n",
        "            title='Discount vs Profit Margin Analysis',\n",
        "            labels={'Discount': 'Discount Rate', 'Profit_Margin': 'Profit Margin (%)'},\n",
        "            height=500\n",
        "        )\n",
        "\n",
        "        # Overall statistics\n",
        "        overall_stats = {\n",
        "            'Metric': ['Total Profit', 'Average Profit Margin', 'Average Discount', 'Total Sales', 'Total Orders'],\n",
        "            'Value': [\n",
        "                f\"₹{self.df['Profit'].sum():.2f}\",\n",
        "                f\"{self.df['Profit_Margin'].mean():.2f}%\",\n",
        "                f\"{self.df['Discount'].mean():.2%}\",\n",
        "                f\"₹{self.df['Sales'].sum():.2f}\",\n",
        "                f\"{len(self.df):,}\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        stats_df = pd.DataFrame(overall_stats)\n",
        "\n",
        "        return fig, profit_df, stats_df\n",
        "\n",
        "    def build_prediction_model(self):\n",
        "        \"\"\"Build machine learning model for sales prediction\"\"\"\n",
        "        if self.df is None:\n",
        "            return \"⚠️ Please load data first\", None\n",
        "\n",
        "        try:\n",
        "            # Prepare features for modeling\n",
        "            df_model = self.df.copy()\n",
        "\n",
        "            # Select features for prediction\n",
        "            categorical_features = ['Category', 'Sub Category', 'City', 'Region', 'State']\n",
        "            numerical_features = ['Month_Num', 'Year', 'Discount', 'Weekday']\n",
        "\n",
        "            # Encode categorical variables\n",
        "            for feature in categorical_features:\n",
        "                le = LabelEncoder()\n",
        "                df_model[feature + '_encoded'] = le.fit_transform(df_model[feature])\n",
        "                self.label_encoders[feature] = le\n",
        "\n",
        "            # Prepare feature matrix\n",
        "            feature_cols = [f + '_encoded' for f in categorical_features] + numerical_features\n",
        "            self.feature_columns = feature_cols\n",
        "\n",
        "            X = df_model[feature_cols]\n",
        "            y = df_model['Sales']\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Scale features\n",
        "            self.scaler = StandardScaler()\n",
        "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "            X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "            # Train Random Forest model\n",
        "            self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "            self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = self.model.predict(X_test_scaled)\n",
        "\n",
        "            # Calculate metrics\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_test, y_pred)\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "            # Model performance summary\n",
        "            performance_data = {\n",
        "                'Metric': ['R² Score', 'Root Mean Squared Error', 'Mean Absolute Error', 'Training Samples', 'Test Samples'],\n",
        "                'Value': [f\"{r2:.4f}\", f\"{rmse:.2f}\", f\"{mae:.2f}\", f\"{len(X_train):,}\", f\"{len(X_test):,}\"]\n",
        "            }\n",
        "\n",
        "            performance_df = pd.DataFrame(performance_data)\n",
        "\n",
        "            # Feature importance\n",
        "            feature_importance_data = []\n",
        "            for feature, importance in zip(feature_cols, self.model.feature_importances_):\n",
        "                feature_importance_data.append({\n",
        "                    'Feature': feature,\n",
        "                    'Importance': importance,\n",
        "                    'Importance_Percentage': f\"{importance*100:.2f}%\"\n",
        "                })\n",
        "\n",
        "            feature_importance_df = pd.DataFrame(feature_importance_data)\n",
        "            feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "            results = \"✅ Model Training Complete!\"\n",
        "\n",
        "            return results, performance_df, feature_importance_df\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error building model: {str(e)}\", None, None\n",
        "\n",
        "    def predict_sales(self, category, sub_category, city, region, state, month, year, discount):\n",
        "        \"\"\"Make sales prediction\"\"\"\n",
        "        if self.model is None:\n",
        "            return \"⚠️ Please build the model first\"\n",
        "\n",
        "        try:\n",
        "            # Create input dataframe\n",
        "            input_data = pd.DataFrame({\n",
        "                'Category': [category],\n",
        "                'Sub Category': [sub_category],\n",
        "                'City': [city],\n",
        "                'Region': [region],\n",
        "                'State': [state],\n",
        "                'Month_Num': [month],\n",
        "                'Year': [year],\n",
        "                'Discount': [discount],\n",
        "                'Weekday': [0]  # Default weekday\n",
        "            })\n",
        "\n",
        "            # Encode categorical variables\n",
        "            for feature in ['Category', 'Sub Category', 'City', 'Region', 'State']:\n",
        "                if feature in self.label_encoders:\n",
        "                    try:\n",
        "                        input_data[feature + '_encoded'] = self.label_encoders[feature].transform(input_data[feature])\n",
        "                    except:\n",
        "                        input_data[feature + '_encoded'] = 0  # Default for unseen categories\n",
        "\n",
        "            # Prepare features\n",
        "            X_input = input_data[self.feature_columns]\n",
        "            X_input_scaled = self.scaler.transform(X_input)\n",
        "\n",
        "            # Make prediction\n",
        "            prediction = self.model.predict(X_input_scaled)[0]\n",
        "\n",
        "            return f\"🔮 **Predicted Sales: ₹{prediction:.2f}**\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error making prediction: {str(e)}\"\n",
        "\n",
        "# Initialize the analytics class\n",
        "analytics = SupermartAnalytics()\n",
        "\n",
        "# Gradio interface functions\n",
        "def load_data_interface(file):\n",
        "    if file is None:\n",
        "        return \"⚠️ Please upload a CSV file\"\n",
        "    return analytics.load_data(file.name)\n",
        "\n",
        "def get_overview():\n",
        "    basic_info, dtypes_df, numeric_stats, sample_data = analytics.get_data_overview()\n",
        "    return basic_info, dtypes_df, numeric_stats, sample_data\n",
        "\n",
        "def category_analysis():\n",
        "    fig, analysis_df = analytics.create_category_analysis()\n",
        "    return fig, analysis_df\n",
        "\n",
        "def temporal_analysis():\n",
        "    fig, yearly_df = analytics.create_temporal_analysis()\n",
        "    return fig, yearly_df\n",
        "\n",
        "def regional_analysis():\n",
        "    fig, regional_df, city_df = analytics.create_regional_analysis()\n",
        "    return fig, regional_df, city_df\n",
        "\n",
        "def profit_analysis():\n",
        "    fig, profit_df, stats_df = analytics.create_profit_analysis()\n",
        "    return fig, profit_df, stats_df\n",
        "\n",
        "def build_model():\n",
        "    results, performance_df, feature_df = analytics.build_prediction_model()\n",
        "    return results, performance_df, feature_df\n",
        "\n",
        "def make_prediction(category, sub_category, city, region, state, month, year, discount):\n",
        "    return analytics.predict_sales(category, sub_category, city, region, state, month, year, discount)\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Supermart Grocery Sales Analytics\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🛒 Supermart Grocery Sales Analytics Dashboard\n",
        "\n",
        "    **Data Science Internship Project**\n",
        "\n",
        "    This interactive dashboard provides comprehensive analysis of grocery sales data including:\n",
        "    - Data exploration and visualization\n",
        "    - Sales performance analysis\n",
        "    - Predictive modeling\n",
        "    - Interactive predictions\n",
        "\n",
        "    **Dataset:** [Download from Kaggle](https://www.kaggle.com/datasets/mohanavamsi/supermart-grocery-sales-retail-analytics-dataset)\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"📁 Data Loading\"):\n",
        "        gr.Markdown(\"### Upload your CSV file to get started\")\n",
        "        file_input = gr.File(label=\"Upload CSV File\", file_types=[\".csv\"])\n",
        "        load_btn = gr.Button(\"Load Data\", variant=\"primary\")\n",
        "        load_output = gr.Textbox(label=\"Status\", lines=3)\n",
        "\n",
        "        load_btn.click(load_data_interface, inputs=[file_input], outputs=[load_output])\n",
        "\n",
        "    with gr.Tab(\"📊 Data Overview\"):\n",
        "        overview_btn = gr.Button(\"Generate Overview\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            overview_text = gr.Textbox(label=\"Dataset Summary\", lines=10)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Column Information\")\n",
        "                dtypes_table = gr.Dataframe(label=\"Data Types & Info\")\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Numerical Statistics\")\n",
        "                stats_table = gr.Dataframe(label=\"Statistical Summary\")\n",
        "\n",
        "        gr.Markdown(\"### Sample Data (First 10 rows)\")\n",
        "        sample_table = gr.Dataframe(label=\"Sample Data\")\n",
        "\n",
        "        overview_btn.click(get_overview, outputs=[overview_text, dtypes_table, stats_table, sample_table])\n",
        "\n",
        "    with gr.Tab(\"📈 Category Analysis\"):\n",
        "        category_btn = gr.Button(\"Analyze Categories\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            category_plot = gr.Plot(label=\"Category Sales Visualization\")\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"### Category Performance Summary\")\n",
        "            category_table = gr.Dataframe(label=\"Category Analysis\")\n",
        "\n",
        "        category_btn.click(category_analysis, outputs=[category_plot, category_table])\n",
        "\n",
        "    with gr.Tab(\"⏱️ Time Series Analysis\"):\n",
        "        temporal_btn = gr.Button(\"Analyze Temporal Trends\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            temporal_plot = gr.Plot(label=\"Temporal Analysis\")\n",
        "\n",
        "        with gr.Row():\n",
        "            gr.Markdown(\"### Yearly Performance Summary\")\n",
        "            yearly_table = gr.Dataframe(label=\"Year-wise Analysis\")\n",
        "\n",
        "        temporal_btn.click(temporal_analysis, outputs=[temporal_plot, yearly_table])\n",
        "\n",
        "    with gr.Tab(\"🗺️ Regional Analysis\"):\n",
        "        regional_btn = gr.Button(\"Analyze Regional Performance\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            regional_plot = gr.Plot(label=\"Regional Analysis\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Regional Summary\")\n",
        "                regional_table = gr.Dataframe(label=\"Regional Performance\")\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Top Cities\")\n",
        "                city_table = gr.Dataframe(label=\"City Performance\")\n",
        "\n",
        "        regional_btn.click(regional_analysis, outputs=[regional_plot, regional_table, city_table])\n",
        "\n",
        "    with gr.Tab(\"💰 Profit Analysis\"):\n",
        "        profit_btn = gr.Button(\"Analyze Profit Margins\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            profit_plot = gr.Plot(label=\"Profit Analysis\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Overall Statistics\")\n",
        "                stats_table = gr.Dataframe(label=\"Summary Statistics\")\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Category-wise Profit\")\n",
        "                profit_table = gr.Dataframe(label=\"Profit by Category\")\n",
        "\n",
        "        profit_btn.click(profit_analysis, outputs=[profit_plot, stats_table, profit_table])\n",
        "\n",
        "    with gr.Tab(\"🤖 ML Model\"):\n",
        "        model_btn = gr.Button(\"Build Prediction Model\", variant=\"primary\")\n",
        "\n",
        "        with gr.Row():\n",
        "            model_status = gr.Textbox(label=\"Model Status\", lines=3)\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Model Performance\")\n",
        "                performance_table = gr.Dataframe(label=\"Performance Metrics\")\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Feature Importance\")\n",
        "                feature_table = gr.Dataframe(label=\"Feature Importance\")\n",
        "\n",
        "        model_btn.click(build_model, outputs=[model_status, performance_table, feature_table])\n",
        "\n",
        "    with gr.Tab(\"🔮 Sales Prediction\"):\n",
        "        gr.Markdown(\"### Make Sales Predictions\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                pred_category = gr.Dropdown(\n",
        "                    choices=[\"Food Grains\", \"Beverages\", \"Snacks & Branded Foods\", \"Fruits & Veggies\",\n",
        "                            \"Egg, Meat & Fish\", \"Oil & Masala\", \"Cleaning & Household\", \"Dairy\", \"Gourmet & World Food\"],\n",
        "                    label=\"Category\", value=\"Food Grains\"\n",
        "                )\n",
        "                pred_sub_category = gr.Textbox(label=\"Sub Category\", value=\"Atta & Flour\")\n",
        "                pred_city = gr.Textbox(label=\"City\", value=\"Chennai\")\n",
        "                pred_region = gr.Dropdown(choices=[\"North\", \"South\", \"East\", \"West\"], label=\"Region\", value=\"South\")\n",
        "                pred_state = gr.Textbox(label=\"State\", value=\"Tamil Nadu\")\n",
        "\n",
        "            with gr.Column():\n",
        "                pred_month = gr.Slider(minimum=1, maximum=12, step=1, label=\"Month\", value=6)\n",
        "                pred_year = gr.Slider(minimum=2016, maximum=2025, step=1, label=\"Year\", value=2024)\n",
        "                pred_discount = gr.Slider(minimum=0, maximum=0.5, step=0.01, label=\"Discount Rate\", value=0.1)\n",
        "\n",
        "        predict_btn = gr.Button(\"Predict Sales\", variant=\"primary\")\n",
        "        prediction_output = gr.Textbox(label=\"Prediction Result\", lines=3)\n",
        "\n",
        "        predict_btn.click(\n",
        "            make_prediction,\n",
        "            inputs=[pred_category, pred_sub_category, pred_city, pred_region, pred_state,\n",
        "                   pred_month, pred_year, pred_discount],\n",
        "            outputs=[prediction_output]\n",
        "        )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    **Instructions:**\n",
        "    1. Upload your CSV file in the \"Data Loading\" tab\n",
        "    2. Explore data insights through various analysis tabs\n",
        "    3. Build the ML model in the \"ML Model\" tab\n",
        "    4. Make predictions in the \"Sales Prediction\" tab\n",
        "\n",
        "    **Note:** This is a comprehensive data science project for internship purposes.\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xueMa4fdL4NJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}